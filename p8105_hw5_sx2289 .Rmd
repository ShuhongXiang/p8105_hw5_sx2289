---
title: "p8105_hw5_solutions"
author: "Shuhong Xiang"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document

---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
	fig.path='Figs/',
  out.width = "90%",
	options(digit = 3)
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

## Problem 1

### Load the data.

```{r}
homcide_df =
  read_csv("homcide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"), 
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL")

```

```{r}
aggregate_df = 
  homcide_df %>%
  group_by(city_state) %>%
  summarise(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

### Prop test for a single city: 

```{r}
prop.test(
  aggregate_df%>%filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df%>%filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>%
  broom::tidy()
```

### Try to iterate:

```{r}
results_df = 
  aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>%
  select(-prop_tests) %>%
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate))+
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2

### Create path_df containing all data from the csv:

```{r}
path_df =
  tibble(
  path = list.files("lda_data"),
) %>%
  mutate(path = str_c("lda_data/", path),
         data = map(path, read_csv)
           )%>%
  unnest(data)

path_df
```

### Clean the datafram:

```{r}
tidy_lda =
  path_df %>%
  mutate(
    path = str_remove_all(path,"lda_data/"), 
    path = str_remove_all(path,".csv")
  ) %>%
  separate(path, into = c("group","subject_id"), sep = 3) %>%
  mutate(
    subject_id = str_remove_all(subject_id, "_"),
    group = str_replace(group,"con","control"),
    group = str_replace(group,"exp","experiment")
  )%>%
  pivot_longer(
    week_1:week_8,
    names_prefix = "week_",
    names_to = "week",
    values_to = "weekly observations"
  )%>%
  mutate(week = as.numeric(week))
tidy_lda
```

### Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups:

```{r}
plot_p2 =
  tidy_lda %>%
  unite("id", c(group, subject_id), sep = "_", remove = F) %>%
  ggplot(aes(x = week,
             y = `weekly observations`)) +
  geom_point(aes(color = group,
                group = id),
             alpha = .5)+
  geom_path(aes(color = group,
                group = as.factor(id)),
            alpha = 0.5) +
  geom_smooth(aes(color = group), method = loess, se = F)

ggsave("plot_p2.png", path = "Figs")

plot_p2
```

From the graph above, we can see that the control groups and experiment groups began the study at the same level of weekly observations. As the study goes on, the control group remain steadily around the same level as beginning  whereas the experiment groups increase gradually. 

## Problem 3

Conduct a simulation to explore power in a one-sample t-test.

### First set n =30 and sigma =5 for the whole problem. Then, set μ=0. Generate 5000 datasets from the model $$x ~ Normal[mu, sigma]$$ :

```{r}
mu_0 <- 0
n_sim <- 5000

set.seed(5000)

 t_test_mu_0 = function(n = 30, mu, sigma = 5) {
  
  t_test_df = tibble(
    
    x = rnorm(n =30, mean = mu, sd = sigma)
  )
  
  t_test_df %>%
    summarise(
      mu_estimated = mean(x),
      p_val = t.test(x, conf.level = 0.95) %>% broom::tidy() %>% pull(p.value),
      mu = mu
    )
}

results_mu_0 = vector("list", n_sim)

for(i in 1 : n_sim){
  
  results_mu_0[[i]] = t_test_mu_0(mu = mu_0)
  
}

sim_mu_0 = bind_rows(results_mu_0)
sim_mu_0
```

### Repeat the above for μ={1,2,3,4,5,6}:

```{r}
set.seed(5000)

sim_t_test = function(n = 30, mu, sigma = 5) {
  
  results_6_mu = vector("list", n_sim)
  
  for(i in 1:n_sim){
    
    results_6_mu[[i]] = t_test_mu_0(mu = mu)
    
  }
  results_sim_t_test = bind_rows(results_6_mu)
}

sim_6_mu = vector("list", 6)

for(i in 1:6){
  
  sim_6_mu[[i]] = sim_t_test(mu = i)
  
}

  results_all = bind_rows(sim_6_mu)

  results_all
```

For the plot, we combine the mu = 0 to make a complete dataset:

```{r}
sim_all = bind_rows(results_all, sim_mu_0)
sim_all
```

### Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.

```{r}
plot_power_test =
sim_all  %>%
  filter(p_val < 0.5) %>%
  mutate(mu = as_factor(mu)) %>%
  count(mu) %>%
ggplot(aes(x = mu, y = n/5000, fill = mu))+
  geom_bar(stat = "identity")+
  labs(
    x = "True Mean(mu)",
    y = "The Proportion of Times the Null was Rejected",
    title = "The Power of the Test"
  )

ggsave("The Power of the Test.png", path = "Figs")
plot_power_test
```
From the bar char above, we can see the power of test increase with the the true value of mu.The proportion of rejecting null reach 1 when mu greater than 3. The effect size is also 

### Make a plot showing the average estimate of μ̂ on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ̂ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. 

```{r message=FALSE, warning=FALSE}
estimated_mu_data = sim_all%>%
  mutate(mu = as.numeric(mu)) %>%
  group_by(mu)%>%
  summarise(mean_estimated_mu = mean(mu_estimated)) %>%
  mutate(group = "Total")

reject_null_data = sim_all%>%
 mutate(mu = as.numeric(mu)) %>%
  filter(p_val < 0.5)%>%
  group_by(mu)%>%
  summarise(mean_estimated_mu = mean(mu_estimated)) %>%
  mutate(group = "Reject Null")

plot_p3_data = combine(estimated_mu_data, reject_null_data)

plot_average_vs_mu = 
ggplot(plot_p3_data, aes(x = mu, y = mean_estimated_mu), group = group, color = group)+
    geom_point()+
  geom_smooth(aes(color = group))+
  labs(
    x = "True Mean(mu)",
    y = "The Average Estimate",
    title = "The Average Estimate vs True mu"
  )
  
ggsave("Average Estimate vs True mu.png", path = "Figs")
plot_average_vs_mu
```

#### Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?

Yes. From the graph above, we cannot see any obvious outliners. Also, the two trend lines are close to each other. Therefore, the sample average of μ̂  across test is consistent with the true μ.

